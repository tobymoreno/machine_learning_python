{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = [\"var\",\"this\",\"function\",\"public\",\"namespace\",\"using\",\"System\",\"public\", \"enum\", \"Function\", \"Module\"];\n",
    "y_labels = [\".cs\", \".js\", \".vb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "txt1 = \"namespace public enum namespace System String\"\n",
    "txt2 = \"this var function var this\"\n",
    "txt3 = \"Function Module Module\"\n",
    "\n",
    "texts.append(txt1)\n",
    "texts.append(txt2)\n",
    "texts.append(txt3)\n",
    "\n",
    "labels = np.array([0, 1, 2], np.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['namespace public enum namespace System String',\n",
       " 'this var function var this',\n",
       " 'Function Module Module']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = []\n",
    "for txt in texts:\n",
    "    xarr = np.zeros(len(vocab))\n",
    "    for item in txt.split():\n",
    "        # get index\n",
    "        xarr[vocab.index(item)] += 1\n",
    "    xs.append(xarr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 1., 2., 0., 1., 0., 1., 0., 0.]),\n",
       " array([2., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 2.])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xstensor = torch.Tensor(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ystensor = torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 1., 2., 0., 1., 0., 1., 0., 0.],\n",
       "         [2., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 2.]]), tensor([0., 1., 2.]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xstensor, ystensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.L1 = torch.nn.Linear(len(vocab), 24)\n",
    "        self.L2 = torch.nn.Linear(24, 12)\n",
    "        self.L3 = torch.nn.Linear(12, len(labels))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.L1(x))\n",
    "        x = F.relu(self.L2(x))\n",
    "\n",
    "        y_pred = self.L3(x)\n",
    "        return y_pred    \n",
    "\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ystensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1211, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1177, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1110, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1076, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1048, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0998, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0972, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0948, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0923, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0898, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0874, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0850, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0826, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0805, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0784, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0764, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0743, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0722, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0701, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0681, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0660, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0639, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0618, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0597, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0576, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0554, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0511, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0489, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0467, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0445, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0422, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0400, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0377, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0354, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0330, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0307, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0283, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0258, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0234, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0209, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0184, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0158, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0132, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0106, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0080, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0053, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9998, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9970, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9941, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9912, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9883, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9793, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9762, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9667, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9635, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9602, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9535, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9397, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9363, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9327, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9000, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8925, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8886, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8849, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8810, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8772, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8694, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8616, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8578, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8540, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8424, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8385, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8346, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8309, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8270, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8045, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7973, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7936, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7900, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7865, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7830, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7795, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7760, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7725, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7692, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7657, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7623, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7590, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7525, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7492, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7428, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7397, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7336, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7306, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7277, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7219, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7049, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6995, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6968, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6941, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6915, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6889, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6837, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6812, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6787, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6761, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6736, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6662, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6638, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6613, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6589, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6565, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6542, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6518, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6494, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6401, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6355, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6331, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6239, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6171, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6148, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6103, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6056, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6034, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5988, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5966, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5943, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5919, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5896, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5872, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5849, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5826, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5803, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5779, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5756, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5732, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5684, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5661, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5636, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5613, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5589, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5565, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5516, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5492, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5419, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5369, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5344, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5319, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5243, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4975, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4919, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4891, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4834, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4804, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4776, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4745, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4716, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4624, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4594, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4562, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4530, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4401, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4335, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4301, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4267, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4234, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4094, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3949, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3912, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3876, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3838, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3801, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3763, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3726, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3687, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3649, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3612, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3572, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3533, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3494, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3455, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3337, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3258, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3139, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2980, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2903, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2823, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2785, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2745, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2668, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2630, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2592, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2554, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2518, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2479, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2442, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2405, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2334, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2227, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2123, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2090, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2023, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1991, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1960, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1928, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1897, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1867, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1836, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1807, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1778, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1748, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1719, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1692, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1664, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1637, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1584, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1533, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1508, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1483, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1414, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1392, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1348, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1327, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1306, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1227, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1208, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1189, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1171, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1153, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1136, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1118, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1102, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0977, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0949, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0936, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0922, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0909, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0896, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0884, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0871, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0847, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0835, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0813, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0801, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0791, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0780, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0769, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0759, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0739, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0730, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0720, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0702, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0693, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0684, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0675, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0667, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0659, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0650, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0642, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0634, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0627, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0619, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0612, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0597, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0590, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0583, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0576, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0570, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0563, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0550, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0544, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0538, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0532, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0526, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0514, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0492, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0487, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0482, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0452, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0439, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0430, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0426, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0417, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0413, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0409, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0405, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0401, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0390, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0383, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0379, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0372, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0369, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0362, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0359, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0356, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0353, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0350, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0346, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0340, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0338, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0335, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0332, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0329, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0321, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0318, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0315, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0313, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0310, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0303, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0298, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0295, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0291, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0284, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0282, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0278, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0273, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0271, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0267, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0265, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0263, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0259, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0258, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0256, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0254, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0250, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0248, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0245, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0243, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0241, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0238, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0235, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0232, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0229, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0227, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0225, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0224, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0221, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    # forward pass\n",
    "    y_pred = model(xstensor)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = criterion(y_pred, ystensor)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = model(xstensor[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 2., 0., 1., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xstensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.data.max(0, keepdim=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newtexts = []\n",
    "new1 = \"public enum namespace System namespace namespace System\"\n",
    "newtexts.append(new1)\n",
    "new2 = \"Function Module\"\n",
    "newtexts.append(new2)\n",
    "new3 = \"this var System public enum\"\n",
    "newtexts.append(new3)\n",
    "\n",
    "newlabels = np.array([0], np.long)\n",
    "\n",
    "newxs = []\n",
    "for txt in newtexts:\n",
    "    xarr = np.zeros(len(vocab))\n",
    "    for item in txt.split():\n",
    "        # get index\n",
    "        xarr[vocab.index(item)] += 1\n",
    "    newxs.append(xarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 1., 3., 0., 2., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]),\n",
       " array([1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.])]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newxstensor = torch.Tensor(newxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = model(newxstensor)\n",
    "#output.data.max(0, keepdim=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.3275, -1.6307, -4.5488],\n",
       "        [-2.0552, -0.3686,  1.9844],\n",
       "        [ 0.4740,  0.9306, -1.4787]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.data.max(1, keepdim=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
