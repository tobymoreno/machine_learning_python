{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 1.0 # a random guess\n",
    "\n",
    "def forward(x):\n",
    "    return x * w\n",
    "\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "\n",
    "loss(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [1.0, 2.0, 3.0]\n",
    "y = [2.0, 4.0, 6.0]\n",
    "\n",
    "w_list = []\n",
    "mse_list = []\n",
    "\n",
    "for w in np.arange(0, 4.1, 0.1):\n",
    "    #print(w)\n",
    "    total_loss = 0\n",
    "    \n",
    "    for x_val, y_val in zip(x, y):\n",
    "#         print(x_val, y_val)\n",
    "        y_pred = forward(x_val)\n",
    "        l = loss(x_val, y_val)\n",
    "        total_loss += l\n",
    "        \n",
    "    w_list.append(w)\n",
    "    mse_list.append(total_loss / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAWbJIsWT0V93AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5de67f630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w_list, mse_list)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$d_loss/dw = 2x(xw - y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def gradient(x, y):\n",
    "    return 2 * x * (x * w - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(1.0, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 4.0\n",
      "epoch :  0 1.260688 4.919240100095999\n",
      "epoch :  10 1.9639333911678687 0.01170720245384975\n",
      "epoch :  20 1.998240525958391 2.7861740127856012e-05\n",
      "epoch :  30 1.9999141657892625 6.630760559646474e-08\n",
      "epoch :  40 1.9999958126624442 1.5780416225633037e-10\n",
      "epoch :  50 1.9999997957248556 3.7555501141274804e-13\n",
      "epoch :  60 1.999999990034638 8.937759877335403e-16\n",
      "epoch :  70 1.9999999995138495 2.1270797208746147e-18\n",
      "epoch :  80 1.9999999999762834 5.062350511130293e-21\n",
      "epoch :  90 1.9999999999988431 1.2047849775995315e-23\n",
      "predict (after training) 4 7.9999999999996945\n"
     ]
    }
   ],
   "source": [
    "x = [1.0, 2.0, 3.0]\n",
    "y = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = 1.0\n",
    "learning_rate = 0.01\n",
    "\n",
    "print(\"predict (before training)\", 4, forward(4))\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x_val, y_val in zip(x, y):\n",
    "        y_pred = forward(x_val)\n",
    "        grad = gradient(x_val, y_val)\n",
    "        w = w - (learning_rate * grad)\n",
    "        l = loss(x_val, y_val)\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"epoch : \", epoch, w, l)\n",
    "\n",
    "print(\"predict (after training)\", 4, forward(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.9999999999996945"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = Variable(torch.Tensor([1.0]), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.loss>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 1.0 # a random guess\n",
    "\n",
    "def forward(x):\n",
    "    return x * w\n",
    "\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "\n",
    "loss(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-44aafa8faa07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Before training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predict (before training)\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Training loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# Before training\n",
    "print(\"predict (before training)\",  4, forward(4).data[0])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        l = loss(x_val, y_val)\n",
    "        l.backward()\n",
    "        print(\"\\tgrad: \", x_val, y_val, w.grad.data[0])\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w.grad.data.zero_()\n",
    "\n",
    "    print(\"progress:\", epoch, l.data[0])\n",
    "\n",
    "# After training\n",
    "print(\"predict (after training)\",  4, forward(4).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 tensor(4.)\n",
      "progress: 0 tensor(7.3159)\n",
      "progress: 10 tensor(0.0174)\n",
      "progress: 20 tensor(4.1433e-05)\n",
      "progress: 30 tensor(9.8744e-08)\n",
      "progress: 40 tensor(2.3283e-10)\n",
      "progress: 50 tensor(9.0949e-13)\n",
      "progress: 60 tensor(9.0949e-13)\n",
      "progress: 70 tensor(9.0949e-13)\n",
      "progress: 80 tensor(9.0949e-13)\n",
      "progress: 90 tensor(9.0949e-13)\n",
      "predict (after training) 4 tensor(8.0000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = Variable(torch.Tensor([1.0]),  requires_grad=True)  # Any random value\n",
    "\n",
    "# our model forward pass\n",
    "\n",
    "def forward(x):\n",
    "    return x * w\n",
    "\n",
    "# Loss function\n",
    "\n",
    "\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "# Before training\n",
    "print(\"predict (before training)\",  4, forward(4).data[0])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        l = loss(x_val, y_val)\n",
    "        l.backward()\n",
    "#         print(\"\\tgrad: \", x_val, y_val, w.grad.data[0])\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w.grad.data.zero_()\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"progress:\", epoch, l.data[0])\n",
    "\n",
    "# After training\n",
    "print(\"predict (after training)\",  4, forward(4).data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do a linear regression using Pytorch all the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = Variable(torch.Tensor([[1.0], [2.0], [3.0]]))\n",
    "y_data = Variable(torch.Tensor([[2.0], [4.0], [6.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create optimizer and loss functions\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.modules.loss.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(500):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.9184465408325195"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = Variable(torch.Tensor([4.0]))\n",
    "new_y = model(new_x)\n",
    "new_y.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do Logistics Regression Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = Variable(torch.Tensor([[1.0],[2.0],[3.0],[4.0]]))\n",
    "y_data = Variable(torch.Tensor([[0.], [0.], [1.], [1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "        \n",
    "        \n",
    "model = Model()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.modules.loss.BCELoss(reduction='mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([[0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7593],\n",
       "        [0.8782],\n",
       "        [0.9428],\n",
       "        [0.9742]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.4487362504005432\n",
      "epoch 50 loss 0.44215553998947144\n",
      "epoch 100 loss 0.43578028678894043\n",
      "epoch 150 loss 0.4296022951602936\n",
      "epoch 200 loss 0.4236137568950653\n",
      "epoch 250 loss 0.41780686378479004\n",
      "epoch 300 loss 0.41217461228370667\n",
      "epoch 350 loss 0.4067099690437317\n",
      "epoch 400 loss 0.4014062285423279\n",
      "epoch 450 loss 0.3962570130825043\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    # makde a prediction / forward pass\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # capture loss and optimize\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(y_pred, y_data)\n",
    "\n",
    "    # calculate gradient descent and propagate backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print statistics\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"epoch\", epoch, \"loss\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3011246621608734 tensor([0], dtype=torch.uint8)\n",
      "0.9990750551223755 tensor([1], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# make a new prediction\n",
    "\n",
    "new_x = Variable(torch.Tensor([1.0]))\n",
    "new_y = model(new_x)\n",
    "\n",
    "print(new_y.data.item(), new_y > 0.5)\n",
    "\n",
    "new_x = Variable(torch.Tensor([10.0]))\n",
    "new_y = model(new_x)\n",
    "\n",
    "print(new_y.data.item(), new_y > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do Diabetes Classification\n",
    "# get the diabetes.csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\spider_work'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Local Disk\n",
      " Volume Serial Number is 927D-F5DC\n",
      "\n",
      " Directory of D:\\spider_work\\data\n",
      "\n",
      "03/15/2019  11:01 AM    <DIR>          .\n",
      "03/15/2019  11:01 AM    <DIR>          ..\n",
      "03/14/2019  04:28 PM            13,539 diabetes.csv.gz\n",
      "               1 File(s)         13,539 bytes\n",
      "               2 Dir(s)  774,522,019,840 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data/diabetes.csv', delimiter=',',dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(759 * .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = Variable(torch.from_numpy(xy[:,0:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_data = Variable(torch.from_numpy(xy[:,[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([759, 8]), torch.Size([759, 1]))"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = Variable(torch.from_numpy(xy[:int(759 * .8),0:-1]))\n",
    "y_train = Variable(torch.from_numpy(xy[:int(759 * .8),[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([607, 8]), torch.Size([607, 1]))"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = Variable(torch.from_numpy(xy[x_train.shape[0]:-1,0:-1]))\n",
    "y_val = Variable(torch.from_numpy(xy[y_train.shape[0]:-1,[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(8, 6)\n",
    "        self.linear2 = torch.nn.Linear(6, 4)\n",
    "        self.linear3 = torch.nn.Linear(4, 1)\n",
    "        \n",
    "        self.sigmoid = torch.sigmoid\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.linear1(x))\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        y_pred = self.sigmoid(self.linear3(x))\n",
    "        return y_pred\n",
    "    \n",
    "model = Model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6498209238052368\n",
      "0.5444836020469666\n",
      "0.5444834232330322\n",
      "0.5444833040237427\n",
      "0.5444833636283875\n",
      "0.5444831252098083\n",
      "0.5444830060005188\n",
      "0.544482946395874\n",
      "0.544482946395874\n",
      "0.5444828271865845\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # let's build the optimizer and loss function\n",
    "\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.2)\n",
    "    optimizer = torch.optim.Adagrad(model.parameters(), lr=0.1)\n",
    "    criterion = torch.nn.modules.loss.BCELoss(reduction='mean')\n",
    "\n",
    "\n",
    "\n",
    "    # let's calculate the loss\n",
    "    \n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "        # let's initialize the gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print loss\n",
    "    if epoch % 50 == 0:\n",
    "        print(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.46357615894039733\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "new_y = model(x_val)\n",
    "for i in range(new_y.shape[0]):\n",
    "    if (new_y[i] > 0.5).item() == y_train[i].item():\n",
    "        num_correct += 1\n",
    "        #print ((new_y[i] > 0.5).item(), y_train[i].item())\n",
    "        \n",
    "print(\"accuracy: \", num_correct/ new_y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do a DatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(DiabetesDataset, self)\n",
    "        xy = np.loadtxt('data/diabetes.csv', delimiter=',',dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = Variable(torch.Tensor(xy[:, 0 : -1]))\n",
    "        self.y_data = Variable(torch.Tensor(xy[:, [-1]]))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiabetesDataset()\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.2)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.1)\n",
    "criterion = torch.nn.modules.loss.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4729618728160858\n",
      "20 0.4221133589744568\n",
      "0 0.49943670630455017\n",
      "20 0.525838315486908\n",
      "0 0.3916226625442505\n",
      "20 0.47642916440963745\n",
      "0 0.31007587909698486\n",
      "20 0.4784518778324127\n",
      "0 0.48001280426979065\n",
      "20 0.5567070841789246\n",
      "0 0.5043805837631226\n",
      "20 0.36243605613708496\n",
      "0 0.4349493384361267\n",
      "20 0.5819852948188782\n",
      "0 0.35351690649986267\n",
      "20 0.5065621137619019\n",
      "0 0.39435866475105286\n",
      "20 0.510428786277771\n",
      "0 0.641165018081665\n",
      "20 0.5962497591972351\n",
      "0 0.5090996623039246\n",
      "20 0.6387606859207153\n",
      "0 0.453039288520813\n",
      "20 0.3863893449306488\n",
      "0 0.5939332246780396\n",
      "20 0.4192889630794525\n",
      "0 0.5293391346931458\n",
      "20 0.536784291267395\n",
      "0 0.3898825943470001\n",
      "20 0.398797869682312\n",
      "0 0.4395953118801117\n",
      "20 0.5422508716583252\n",
      "0 0.40471842885017395\n",
      "20 0.42681965231895447\n",
      "0 0.4740414321422577\n",
      "20 0.561590850353241\n",
      "0 0.5227285623550415\n",
      "20 0.5449935793876648\n",
      "0 0.530718982219696\n",
      "20 0.5605756640434265\n",
      "0 0.5233448147773743\n",
      "20 0.5638911724090576\n",
      "0 0.3846267759799957\n",
      "20 0.5026983618736267\n",
      "0 0.5096893310546875\n",
      "20 0.4414781928062439\n",
      "0 0.32999566197395325\n",
      "20 0.4789140820503235\n",
      "0 0.4556722044944763\n",
      "20 0.5249331593513489\n",
      "0 0.6112887859344482\n",
      "20 0.45650869607925415\n",
      "0 0.4502509832382202\n",
      "20 0.40454724431037903\n",
      "0 0.4834524095058441\n",
      "20 0.35242167115211487\n",
      "0 0.42991963028907776\n",
      "20 0.3371376395225525\n",
      "0 0.4088349938392639\n",
      "20 0.5240446925163269\n",
      "0 0.4170452952384949\n",
      "20 0.3667537271976471\n",
      "0 0.36323726177215576\n",
      "20 0.43416815996170044\n",
      "0 0.5465840101242065\n",
      "20 0.4225198030471802\n",
      "0 0.6627148985862732\n",
      "20 0.3681381642818451\n",
      "0 0.41164812445640564\n",
      "20 0.5301877856254578\n",
      "0 0.42180386185646057\n",
      "20 0.5189847946166992\n",
      "0 0.525862455368042\n",
      "20 0.36006924510002136\n",
      "0 0.3507436513900757\n",
      "20 0.3499998450279236\n",
      "0 0.5344997048377991\n",
      "20 0.4661419987678528\n",
      "0 0.3392961621284485\n",
      "20 0.43706023693084717\n",
      "0 0.5919924974441528\n",
      "20 0.4557962715625763\n",
      "0 0.3811454176902771\n",
      "20 0.5267894864082336\n",
      "0 0.34076187014579773\n",
      "20 0.576904833316803\n",
      "0 0.46446865797042847\n",
      "20 0.549565851688385\n",
      "0 0.4023902118206024\n",
      "20 0.40081682801246643\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "#     print(epoch)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        #forward pass\n",
    "        y_pred = model(inputs)\n",
    "        #print(y_pred)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        #print loss\n",
    "#         print(epoch)\n",
    "        if epoch % 10 and i % 20 == 0:\n",
    "            print(i, loss.item())        \n",
    "        \n",
    "        # initialize gradient descent\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Variable(torch.Tensor(xy[:10, 0 : -1 ]))) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy[:10, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
