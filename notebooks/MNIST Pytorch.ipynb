{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable \n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torchvision.datasets' from 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Anaconda3_64\\\\lib\\\\site-packages\\\\torchvision\\\\datasets\\\\__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ./mnist_data/\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Local Disk\n",
      " Volume Serial Number is 927D-F5DC\n",
      "\n",
      " Directory of D:\\spider_work\n",
      "\n",
      "03/16/2019  11:12 AM    <DIR>          .\n",
      "03/16/2019  11:12 AM    <DIR>          ..\n",
      "03/16/2019  11:09 AM    <DIR>          .ipynb_checkpoints\n",
      "03/15/2019  09:16 PM            35,788 Classify Code Base.ipynb\n",
      "03/15/2019  09:26 PM            35,973 Classify Code Base-Copy1.ipynb\n",
      "03/15/2019  09:27 PM            17,354 code_analysis.ipynb\n",
      "03/15/2019  09:37 PM            19,297 code_analysis-Copy1.ipynb\n",
      "03/15/2019  11:03 AM    <DIR>          data\n",
      "03/14/2019  11:28 AM           103,557 dir_scan.txt\n",
      "03/11/2019  02:50 PM    <DIR>          exp_spider_imo\n",
      "10/31/2018  07:56 AM       428,028,722 exp_spider_imo.zip\n",
      "03/14/2019  04:46 PM            38,676 file type classification.ipynb\n",
      "03/16/2019  11:12 AM             3,708 Image Classification using CNN.ipynb\n",
      "03/16/2019  11:11 AM            19,688 MNIST Pytorch.ipynb\n",
      "03/15/2019  02:39 PM    <DIR>          mnist_data\n",
      "03/13/2019  06:45 PM    <DIR>          modtracker-master@888c89070ee\n",
      "03/11/2019  03:21 PM        22,733,031 modtracker-master@888c89070ee.zip\n",
      "03/15/2019  02:21 PM            47,507 Pytorch Machine Learning Primer.ipynb\n",
      "03/15/2019  02:36 PM             3,454 Softmax Loss.ipynb\n",
      "03/15/2019  02:23 PM             6,807 Test.ipynb\n",
      "03/15/2019  03:48 PM            75,788 Test2.ipynb\n",
      "03/13/2019  12:02 PM    <DIR>          wwwroot\n",
      "03/11/2019  02:58 PM        57,183,496 wwwroot.zip\n",
      "              15 File(s)    508,352,846 bytes\n",
      "               8 Dir(s)  774,661,476,352 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.L1 = torch.nn.Linear(28 * 28, 520)\n",
    "#         self.L2 = torch.nn.Linear(520, 320)\n",
    "#         self.L3 = torch.nn.Linear(320, 240)\n",
    "#         self.L4 = torch.nn.Linear(240, 120)\n",
    "#         self.L5 = torch.nn.Linear(120, 10)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # reshape\n",
    "#         x = x.view(-1, 28 * 28)\n",
    "#         x = F.relu(self.L1(x))\n",
    "#         x = F.relu(self.L2(x))\n",
    "#         x = F.relu(self.L3(x))\n",
    "#         x = F.relu(self.L4(x))\n",
    "#         y_pred = self.L5(x)\n",
    "#         return y_pred    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(784, 520)\n",
    "        self.l2 = nn.Linear(520, 320)\n",
    "        self.l3 = nn.Linear(320, 240)\n",
    "        self.l4 = nn.Linear(240, 120)\n",
    "        self.l5 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)\n",
    "\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=784, out_features=520, bias=True)\n",
       "  (l2): Linear(in_features=520, out_features=320, bias=True)\n",
       "  (l3): Linear(in_features=320, out_features=240, bias=True)\n",
       "  (l4): Linear(in_features=240, out_features=120, bias=True)\n",
       "  (l5): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# loss result from logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.437357\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.408980\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.522663\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.416532\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.446243\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.241328\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.214510\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.181735\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.263920\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.338880\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.350732\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.313260\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.243402\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.325086\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.479992\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.235501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0047, Accuracy: 9093/10000 (90%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.136563\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.264378\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.208050\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.488228\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.109092\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.443764\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.301298\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.193880\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.347144\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.199039\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.252732\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.442792\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.113935\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.342755\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.223267\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.176329\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 9361/10000 (93%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.159839\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.272990\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.248502\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.190515\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.079263\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.323858\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.108783\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.160122\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.149712\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.218406\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.124457\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.227523\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.149547\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.308098\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.194989\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.156744\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 9386/10000 (93%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.214113\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.288765\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.236528\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.133572\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.310000\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.073763\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.227883\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.171679\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.161103\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.220443\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.094349\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.184875\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.177180\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.417456\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.271459\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.130741\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 9570/10000 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.148783\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.059660\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.135703\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.100391\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.065188\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.154535\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.071006\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.041589\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.072564\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.133448\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.114541\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.093683\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.355989\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.132831\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.237233\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.114520\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 9592/10000 (95%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.295127\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.169485\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.183506\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.036852\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.069759\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.190357\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.135632\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.117731\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.033584\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.081591\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.110974\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.106378\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.133575\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.106773\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.164615\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.096595\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 9649/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.043542\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.116801\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.043025\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.173983\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.043167\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.063898\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.065795\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.230861\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.143352\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.043170\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.114814\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.101127\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.036187\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.078825\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.098922\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.113363\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 9665/10000 (96%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.016948\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.081641\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.052503\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.035163\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.076525\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.101599\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.166938\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.017907\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.015577\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.041339\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.017441\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.071402\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.054161\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.094201\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.076921\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.147892\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9687/10000 (96%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.043189\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.025418\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.064822\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.043971\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.027009\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.056101\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.032035\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.047225\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.084007\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.046834\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.033945\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.076512\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.030331\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.152307\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.057992\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.076386\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 9734/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train():\n",
    "#     for idx, (data, target) in enumerate(train_loader):\n",
    "#     #     print(data.shape)\n",
    "#         x = Variable(data)\n",
    "#         y = Variable(target)\n",
    "#         y_pred = model(x)\n",
    "#         optimizer.zero_grad()\n",
    "#         #print(y_pred.shape, y.shape)\n",
    "\n",
    "#         loss = criterion(y_pred, y)\n",
    "#         if(idx % 60 == 0):\n",
    "#             print(loss.item())\n",
    "\n",
    "#         loss.backward()\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output.shape, target.shape)\n",
    "        loss = criterion(output, target)\n",
    "#         break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 60 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "        \n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    train()\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
